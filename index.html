<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="description">
  <meta name="keywords" content="Safety">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Safety Snowball Agent (SSA)</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.16.0/gradio.js"></script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }
</style>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Safety Snowball Agent (SSA):</h1>
            <h3 class="title is-3 publication-title">A Novel Framework for Testing LVLM Vulnerabilities</h3>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2411.11496" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/gzcch/Safety_Snowball_Agent" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-centered">
          ðŸ”¥<span style="color: #ff3860">[NEW!]</span> SSA Released!
          <br><br>
          Exploring vulnerabilities in LVLMs using safe inputs.
        </h4>
      </div>
    </div>
  </section>

  <section class="section" style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Large Vision-Language Models (LVLMs) have achieved remarkable progress by seamlessly integrating visual inputs into the latent space of Large Language Models (LLMs). These advancements have driven widespread adoption across diverse real-world applications, including human-computer interaction, recommender systems, creative writing, and precision agriculture. However, LVLMs also pose risks of generating unsafe content (e.g., violence, nudity, etc.), particularly due to unforeseen vulnerabilities introduced by the visual modality, resulting in ethical and societal concerns. Understanding and identifying these vulnerabilities in LVLMs, especially their non-compliance with established AI safety policies, has become a focus in the field.

              In this work, we explore vulnerabilities of LVLMs from a novel perspective: using safe inputs to trigger unsafe content generation by leveraging the inherent properties of LVLMs. Specifically, we are the first to disclose that any safe image can potentially be exploited to induce LVLMs to generate harmful outputs by combining additional safe images and prompts. We investigate the "safe-input, unsafe-output" phenomenon in LVLMs and identify two key insights:

              <ol type="1">
                <li><b>Universal Reasoning Abilities</b>: LVLMs exhibit advanced reasoning capabilities, enabling them to integrate and interpret complex relationships between visual and textual inputs. While this facilitates sophisticated content understanding and generation, it can also lead to overinterpretation, where the model infers unintended relationships across safe inputs and generates undesired harmful outputs.</li>
                <li><b>Safety Snowball Effect</b>: We observe that an initial unsafe statement leads to further harmful content generation. We term this effect the "safety snowball effect."</li>
              </ol>

              Building on these findings, we propose Safety Snowball Agent (SSA), a novel agent-based jailbreak framework targeting LVLMs by leveraging their universal reasoning abilities and the safety snowball effect. Our experiments demonstrate that SSA outperforms baseline methods by exploiting nearly any image to generate harmful content, achieving a jailbreak success rate of 88.6% against the most advanced LVLMs. This underscores a new challenge for AI safety protection in LVLMs.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5886/5886212.png"> Understanding LVLM Vulnerabilities</h2>
      </div>
    </div>

    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              We identify two key properties of LVLMs that contribute to the "safe-input, unsafe-output" behaviors:

              <ul>
                <li><b>Universal Reasoning Abilities</b>: LVLMs can overinterpret relationships across safe inputs, leading to undesired harmful outputs.</li>
                <li><b>Safety Snowball Effect</b>: An initial unsafe response can escalate into progressively more harmful outputs.</li>
              </ul>

              Our proposed Safety Snowball Agent (SSA) leverages these properties to explore vulnerabilities in LVLMs.
            </p>
          </div>

          <div class="columns is-centered has-text-centered">
            <div class="column is-six-fifths">
              <img id="teaser" width="70%" src="images/SSA_arch.png">
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/3515/3515174.png"> Performance Evaluation</h2>
      </div>
    </div>

    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4"><img id="painting_icon" width="4%" src="https://cdn-icons-png.flaticon.com/512/1698/1698535.png"> Jailbreak Success Rate</h2>

          <div>
            <img id="painting_icon" width="65%" src="images/case_results.png">
          </div>

          <p style="font-family:Times New Roman"><b>SSA demonstrates the highest capability to exploit diverse images for generating harmful content, achieving a jailbreak success rate of 88.6% against advanced LVLMs.</b></p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Examples of Unsafe Output Generation</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-4">Case Study: Safe Inputs Leading to Unsafe Outputs</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <img id="teaser" width="35%" src="images/case_intro.png">
        <!-- Replace with actual images showcasing the cases -->
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{ssa2024safetysnowball,
      author={Your Name and Collaborators},
      title={Safety Snowball Agent: A Novel Framework for Testing LVLM Vulnerabilities}, 
      year={2024},
      eprint={arXiv:2411.11496},
}
      </code></pre>
    </div>
  </section>

  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgement</h2>
      <p>
        This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. We thank the LVLM community for their valuable insights and discussions.
      </p>

      <p>
        <b>Usage and License Notices</b>: The data, code, and models are intended and licensed for research use only. They are also restricted to uses that follow the license agreements of the underlying models and datasets.
      </p>
    </div>
  </section>

  <script>
    // JavaScript content remains unchanged
  </script>

</body>

</html>
